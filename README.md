# Offensive–Defensive AI Framework for CyberSecurity  
### *A Dual Multi-Agent AI Architecture for Modern Cyber Operations*

---

## Overview

This repository contains the complete research, LaTeX source, diagrams, and proof-of-concept (PoC) implementations for a dual-paradigm cybersecurity study:

---

### **1. Offensive Paper – LRMAM**

**LRMAM — Large Remote Multi-Agent Malware**  
A conceptual model describing how future malware may evolve by delegating intelligence to external AI multi-agent systems, using remote LLMs, adaptive prompt templates, and distributed orchestration.

---

### **2. Defensive Paper – DMAS**

**DMAS — Defensive Multi-Agent AI System**  
A two-layer cyber defence architecture consisting of distributed Edge-Agents and a centralised Core-Agent Swarm performing structured AI reasoning, correlation, and policy-governed mitigation.

---

Together, these works form a unified research perspective on the next generation of **AI-native cybersecurity**, where both attackers and defenders use autonomous multi-agent AI systems.

---

## Purpose of This Repository

This repository is intended for:

- Researchers exploring new AI-driven threat and defence models  
- Security engineers studying multi-agent architectures  
- Educators needing structured examples of AI-for-cybersecurity  
- Students learning secure AI orchestration  
- Policy/governance analysts evaluating autonomous cyber systems  

> **All materials here are scientific, safe, and non-destructive.**

---

## Ethics & Safety

This repository **does not contain malware** or harmful code.

All PoC implementations:

- ✔ use synthetic data only  
- ✔ run in sandboxed environments  
- ✔ avoid harmful or privileged operations  
- ✔ simulate AI-driven logic without contacting external services  
- ✔ include policy gates and action safety filters  

This project adheres to:

- **NIST AI Risk Management Framework (AI RMF)**  
- **NIST Privacy Framework**  
- **OECD AI Principles**  
- **NIST safe cybersecurity testing guidelines**

> The offensive model (**LRMAM**) is presented for **academic awareness**, not operational use.

---
